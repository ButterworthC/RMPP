<html>
<head>
<title>e-Portfolio for Research Methods and Professional Practice course</title>

<style>
table {
    border-collapse: collapse;
    margin: 20px 0;
    font-family: Arial, sans-serif;
}
th {
    background-color: #4CAF50; /* Header background color */
    color: white; /* Header text color */
    padding: 10px;
}
td {
    padding: 8px;
    text-align: left;
}
th, td {
    border: 1px solid #ddd; /* Single line border */
}

.left-align {
    text-align: left;
}

.discussion-box {
  background-color: #f0f0f0;  /* Set the background color */
  padding: 20px;              /* Add padding to create a slight indent */
  border: none;               /* Remove any border */
  margin: 20px 0;             /* Add margin for spacing */
  border-radius: 10px;        /* Optional: add rounded corners */
  box-shadow: none;           /* No shadow, keeps it clean */
}

.discussion-box p {
  margin: 10px 0;             /* Space out paragraphs */
}

.quote {
  margin-left: 40px;  /* Indents the paragraph from the left */
  margin-right: 40px; /* Indents the paragraph from the right */
  font-style: italic; /* Optional: Italicize the text for a quote */
}

</style>
</head>

<body style="background-color: ffffbb; margin-left: 50px; margin-right: 50px;">
<h1>e-Portfolio for Research Methods and Professional Practice course</h1>
<h2>Chris Butterworth</h2>
<!-- <p><a href="about-me.html">About me</a></p> -->
<p><a href="about-me.html">About me</a></p>
<!-- <p><a href="prep.html">Preparation for Research Methods and Professional Practice module</a></p> -->

<p>GitHub-hosted version: <a href="https://butterworthc.github.io/RMPP/e-Portfolio.html">butterworthc.github.io/RMPP/e-Portfolio.html</a></p>
<p>Online repository, showing commit descriptions: <a href="https://github.com/ButterworthC/RMPP">https://github.com/ButterworthC/RMPP</a></p>


<h2>Unit 1: <!-- Introduction to Research Methods. The Scientific Investigation and -->
Ethics in Computing</h2>
<p>I found the Association for Computing Machinery's Code of Ethics (<a href="#acm2018">ACM, 2018</a>) and its case studies (<a href="#acmnd">ACM, n.d.</a>), 
and the British Computer Society's Code of Conduct (<a href="#bcs">BCS, 2022</a>),
to be rooted in common sense but, as BCS admits: "It is expected that these rules and professional standards 
will be higher than those established by the general law 
and that they will be enforced through disciplinary action which can result in expulsion from membership."
In other words, these rules are toothless. A statutory framework would have more of a bite and would help close the gap in compliance.</p>
<h3>Reflective Activity 1: Ethics in Computing in the age of Generative AI [943 words]</h3>
<p>The above (<a href="#acm2018">ACM, 2018</a>; <a href="#bcs">BCS, 2022</a>) were just two governance frameworks but a recent paper (<a href="#correa">Corr&ecirc;a et al., 2023</a>) 
examines 200 such frameworks, in the form of a survey of surveys,
aiming "to determine whether a consensus exists regarding the normative discourse presented in ethical guidelines surrounding AI development"
and concluding (like me) that there is a "need for comprehensive and enforceable frameworks to guide ethical AI development and usage."</p>
<p>The authors extracted from the literature a set of 17 principles, which they listed as:</p>
<blockquote class="quote">“accessibility, accountability, auditability, beneficence/non-maleficence, dignity, diversity, freedom/autonomy, human-centeredness, inclusion, intellectual property, justice/equity, open source/fair competition, privacy, reliability, solidarity, sustainability, and transparency/explainability.”<br>(<a href="#correa">Corr&ecirc;a et al., 2023</a>)</blockquote>
<p>Although this list of principles was virtually universal, there were differences in emphasis from region to region, according to cultural variations.  In the western world, the reverence for individuality causes the prioritization of principles such as dignity, freedom/autonomy and privacy, whereas in the eastern world, where individuality is more likely to be subsumed by collective interests (Hofstede, 2011), principles such as accountability, auditability, reliability and solidarity are favoured (<a href="#correa">Corr&ecirc;a et al., 2023</a>).</p>
<p>The analysis was multidimensional, cutting across the above regional cultural variations and existing legislation in different countries, also considering each paper’s type (which I think means research vs review), the regulations it advocates, its normativity, and the perceived urgency of the study.  Another dimension was the type of code the different researchers wanted their proposed regulations to form, divided into legislation, voluntary codes, and “recommendation,” which I take to be neither of the preceding.  Another was “normative strength,” which the authors define as the split between recommendations for guidelines and for legally binding regulations, which confused me because the previous dimension seems to have covered that.  The final dimension was “impact scope,” by which the authors meant the timescale over which each paper’s AI type will be relevant, divided into “long-termism,” “short-termism” and a third category for both.</p>
<p>I found the analysis of all this data in its multiple dimensions to be quite crude, not made more sophisticated by the presentation of the results in Power BI™.  The authors found regional variations in the numbers of papers published and commented on the rapid growth of these in China relative to the United States, also observing the dominance of India in the AI field.  In my opinion it would be enough to have representative papers from each region for comparison of their priorities, without spending too much time comparing their volumes.  I feel I am justified in this by the authors’ contrast between the number of papers from Africa (one!) and the number of “African Union member states [which] possess data protection and privacy legislation” (seventeen) (Kiemde & Kora, 2022).  However, the lack of activity in the United States could be attributed to the prevalence there of a developing country environment where regulation is kept to a minimum in order to release entrepreneurial forces (Schaake, 2024).</p>
<p>I was surprised to see that only 25% of the papers were from academic institutions.  The most prolific organisations were governments, private corporations (also a surprise), NGO’s and non-profits.  It is good to see that the industry is not afraid to police itself.  The next categories were international organisations, and at 13%, professional associations, which makes sense, as there are only one or two relevant ones in each country (AAAI, 2025).</p>
<p>The authors see the average “normative strength” as low:</p>
<blockquote class="quote">This lack of convergence to a more "government-based" form of regulation reflects in the normative strength of these documents, where the vast majority (98%) only serve as "soft laws," i.e., guidelines that do not entail any form of a legal obligation…<br>(<a href="#correa">Corr&ecirc;a et al., 2023</a>)</blockquote>
<p>I did not see much value in the impact scope, or timescale analysis.  The fact that academic institutions look further ahead than companies seems unsurprising and natural to me.</p>
<p>After going through these dimensions, the authors note that only about half the papers reviewed actually declared their objectives, and that “most of the documents only prescribe normative claims without the means to achieve them” (<a href="#correa">Corr&ecirc;a et al., 2023</a>).  I think I might have excluded many of the papers that failed to make strong cases for their codes.  With only 200 papers this review was never going to be exhaustive anyway.</p>
<p>In the final remarks of <a href="#correa">Corr&ecirc;a et al. (2023)</a>, there seems to be a lack of firm conclusions as to how to harmonise AI codes of ethics worldwide, although their identification of 17 principles would make a good starting point for further analysis.  If I were conducting this, I would grade each paper according to each of those principles and then develop a logical ontology called “AI Ethics” or something similar, which could be used to develop a “common ground” set of principles, and identify areas in which haggling could take place between organisations seeking to produce a unified code of ethics or even supranational legislation.</p>
<p>Unlike the above paper, the British Computer Society’s explanation of ethics in AI (Deckard, 2023) is not a review paper and does not appear in a peer-reviewed journal but is a page on the BCS website explaining AI ethics to those considering getting into the field.  It does emphasise that AI is an evolving field and that the ethical framework surrounding it must evolve too.  The paper encourages those in the field of AI to get involved in the development of an ethical framework.  I do not see how anyone could object to its recommendations to understand ethics, catch up with the technology and stay abreast of it, communicate, collaborate, and participate in the AI ethics debate.  Perhaps the first paper and those it spawns should be a central part of this debate.</p>


</p>







<h2>Unit 2: Research Questions, the Literature Review and the Research Proposal</h2>
<h3>Research Proposal Outline</h3>
**********
<pre>
You should also take some time to consider your research proposal which could be based around the area you have chosen to investigate in your literature review 
or the topic of your capstone project (MSc students).
</pre>
don't forget to replace the above with the answer<br>
**********

<h2>Unit 3: Methodology and Research Methods</h2>
<h3>Research Proposal Review</h3>
**********
<pre>
Considering your thoughts on your chosen area of interest for your project:

    Which of the methods described in this week's reading would you think would suit your purpose?
    Which data collection methods would you consider using?
    Which required skills will you need to have or develop for the chosen project?

Note that you may find that you could be using a mixture of both the research methods and the data collection methods. 
These considerations will be included in your presentation of the Project Proposal in unit 10.
</pre>
don't forget to replace the above with the answers!<br>
**********

<h3>Peer Review Activity</h3>
<p>
I selected two papers on image classification:

<table>
<tr><td></td><th>Image Classification with<br>Classic &amp; Deep Learning Techniques</th><th>A Survey on Semi- Self- and Unsupervised<br>Learning for Image Classification</th></tr>
<tr><th style="text-align: left;">Source</th><td><a href="#lorente">Lorente et al. (2021)</a></td><td><a href="#schmarje">Schmarje et al. (2021)</a></td></tr>
<tr><th style="text-align: left;">Type</th><td>Experimental study</td><td>Survey</td></tr>
<tr><th style="text-align: left;">Purpose</th><td>To compare various kinds of image classifier</td><td>To "compare 34 methods in detail based on their performance"</td></tr>
<tr><th style="text-align: left;">Problem</th><td>Determining the most effective method under different circumstances</td><td>Scarcity of labeled data in training high-performing classifiers</td></tr>
<tr><th style="text-align: left;">Objective</th><td>To assess the performance of these techniques "in terms of accuracy and loss"</td><td>To identify trends, categorize existing approaches, and highlight future research directions</td></tr>
<tr><th style="text-align: left;">Contribution</th><td>Offering insights for researchers and practitioners in choosing suitable classifiers</td><td>Making it easier for new researchers to understand the field's progress and open challenges</td></tr>
<tr><th style="text-align: left;">Appropriateness<br>of research methodology</th><td>It directly tests different classification techniques on benchmark datasets, enabling objective comparisons</td><td>A survey-based approach is appropriate since the goal is to provide a broad synthesis rather than conduct original experiments</td></tr>
<tr><th style="text-align: left;">Appropriateness<br>of data collection<br>and analysis</th><td>Uses widely accepted datasets and performance metrics</td><td>Based on reviewing past studies rather than conducting new experiments</td></tr>
<tr><th style="text-align: left;">Support for claims and conclusions</th><td>Includes "accuracy and loss" comparisons to justify its claims but significance testing could strengthen its conclusions</td><td>Relies on external studies to support its claims</td></tr>
<tr><th style="text-align: left;">Enhancements</th><td>I would test on more datasets to confirm accuracy, and change some parameters to ensure the model is optimised</td><td>Perhaps include a side-by-side comparison of methodologies, and talk more about potential biases</td></tr>

</table>

</p>



<h2>Unit 4: Case Studies, Focus Groups and Observations</h2>
<h3>Unit 4 Seminar: Case Study on Privacy</h3>
Beth asks Ricardo to retrieve names and addresses, so she can contact people for information and permission to use it.<br>
<ul>
<li>As Ricardo is not responsible for determining allowable access, he should not release it to Beth, as this would be a violation of GDPR's
lawfulness, fairness, and transparency principles (<a href="#eu2016">European Union, 2016</a>).</li>
<li>If he did have authority, he should still respect people's privacy rights (under GDPR again) to maintain public trust.</li>
<li>Beth should not contact people directly to let them opt in but go through her department.</li>
<li>For Beth to proceed she should perhaps adjust the boundary under study until she reaches 50% coverage, but this could skew the data.</li>
</ul>

 
<h2>Unit 5: Interviews, Survey Methods, and Questionnaire Design</h2>
<h3>Reflective Activity 2: Inappropriate Use of Surveys</h3>
<p>

</p>









<h2>Unit 6: Quantitative Methods - Descriptive and Inferential Statistics</h2>

<h2>Unit 7: Inferential Statistics and Hypothesis Testing</h2>

<h2>Unit 8: Data Analysis and Visualisation</h2>

<h2>Unit 9: Validity and Generalisability in Research</h2>

<h2>Unit 10: Research Writing</h2>

<h2>Unit 11: Professional Development</h2>

<h2>Unit 12: Project Management and Managing Risk</h2>


<p></p>



<p>&nbsp;</p>
<p>&nbsp;</p>

<h2>References</h2>

<p id="aaai">AAAI. (2025) Association for the Advancement of Artificial Intelligence List of Societies. Available from: <a href="https://aaai.org/about-aaai/aaai-resources/ai-international/societies/">aaai.org/about-aaai/aaai-resources/ai-international/societies/</a> [Accessed 4 March 2025].</p>
<p id="acm2018">ACM. (2018) ACM Code of Ethics and Professional Conduct. Available from: <a href="https://www.acm.org/code-of-ethics">https://www.acm.org/code-of-ethics</a> [Accessed 31 January 2025].</p>
<p id="acmnd">ACM. (n.d.) Code of Ethics: Case studies. Available from: <a href="https://www.acm.org/code-of-ethics/case-studies">https://www.acm.org/code-of-ethics/case-studies</a> [Accessed 31 January 2025].</p>
<p id="bcs">BCS. (2022) BCS, The Chartered Institute for IT. The Code of Conduct. Available from: <a href="https://www.bcs.org/media/2211/bcs-code-of-conduct.pdf">https://www.bcs.org/media/2211/bcs-code-of-conduct.pdf</a> [Accessed 1 February 2025]</p>
<p id="correa">Corr&ecirc;a, N.K. et al. (2023) Worldwide AI ethics: A review of 200 guidelines and recommendations for AI governance. <i>Patterns</i> 4(10). DOI: <a href="https://doi.org/10.1016/j.patter.2023.100857">https://doi.org/10.1016/j.patter.2023.100857</a></p>
<p id="deckard">Deckard, R. (2023) <i>What are Ethics in AI</i>. BCS. Available from <a href="https://www.bcs.org/articles-opinion-and-research/what-are-ethics-in-ai/">www.bcs.org/articles-opinion-and-research/what-are-ethics-in-ai/</a> [Accessed 2 February 2025].</p>
<p id="eu2016">European Union (2016) Regulation (EU) 2016/679 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regard to the processing of personal data and on the free movement of such data, and repealing Directive 95/46/EC (General Data Protection Regulation). Official Journal of the European Union L 119, 4 May, pp. 1-88. Available from: <a href="https://eur-lex.europa.eu/eli/reg/2016/679/oj">https://eur-lex.europa.eu/eli/reg/2016/679/oj</a> [Accessed: 19 February 2025].</p>
<p id="hofstede">Hofstede, G. (2011) Dimensionalizing Cultures: The Hofstede Model in Context. <i>Online Readings in Psychology and Culture</i> 2(1). DOI: <a href="https://doi.org/10.9707/2307-0919.1014">doi.org/10.9707/2307-0919.1014</a></p>
<p id="kiemde">Kiemde, S.M.A. &amp; Kora, A.D. (2022) Towards an ethics of AI in Africa: rule of education. <i>AI and Ethics</i> 2: 35-40. DOI: <a href="https://doi.org/10.1007/s43681-021-00106-8">doi.org/10.1007/s43681-021-00106-8</a></p>
<p id="lorente">Lorente, O., Riera, I. &amp; Rana, A. (2021) Image Classification with Classic and Deep Learning Techniques. <i>arXiv</i>. DOI: <a href="https://doi.org/10.48550/arXiv.2105.04895">doi.org/10.48550/arXiv.2105.04895</a></p>
<!-- <p id="priya">Priya, A. (2021) Case Study Methodology of Qualitative Research: Key Attributes and Navigating the Conundrums in its Application. <i>Sociological bulletin</i>. 70(1): 94–110. DOI: <a href="https://doi.org/10.1177/0038022920970318">doi.org/10.1177/0038022920970318</a></p> -->
<p id="schaake">Schaake, M. (2024) Lobbying for unfettered innovation is bad for democracy. <i>Financial Times</i>. Available from: <a href="https://www.ft.com/content/ab2761bd-ace7-428b-aa3e-b7412ef69b48">www.ft.com/content/ab2761bd-ace7-428b-aa3e-b7412ef69b48</a> [Accessed 4 February 2025].</p>
<p id="schmarje">Schmarje, L. et al. (2021) A Survey on Semi- Self- and Unsupervised Learning for Image Classification. <i>IEEE Access</i>. DOI: <a href="http://dx.doi.org/10.1109/ACCESS.2021.3084358">dx.doi.org/10.1109/ACCESS.2021.3084358</a></p>

<p>Power BI™ is a trademark of Microsoft Corporation</p>

<p>&nbsp;</p>
<p>&nbsp;</p>

</body>
</html>