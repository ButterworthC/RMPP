<!DOCTYPE html>
<html lang="en">

<head>
<meta charset="UTF-8">
<title>e-Portfolio for Research Methods and Professional Practice course</title>

<style>
html, body {
    background-color: #ffffbb; /* Apply to both elements */
    margin-left: 50px;
    margin-right: 50px;
    line-height: 1.5;
    font-size: 12pt;
}

table {
    border-collapse: collapse;
    margin: 20px 0;
    font-family: Arial, sans-serif;
}
th {
    background-color: #4CAF50; /* Header background color */
    color: white; /* Header text color */
    padding: 10px;
}
td {
    padding: 8px;
    text-align: left;
    vertical-align: top;
}
th, td {
    border: 1px solid #ddd; /* Single line border */
}

.left-align {
    text-align: left;
}

.discussion-box {
  background-color: #f0f0f0;  /* Set the background color */
  padding: 20px;              /* Add padding to create a slight indent */
  border: none;               /* Remove any border */
  margin: 20px 0;             /* Add margin for spacing */
  border-radius: 10px;        /* Optional: add rounded corners */
  box-shadow: none;           /* No shadow, keeps it clean */
}

.discussion-box p {
  margin: 10px 0;             /* Space out paragraphs */
}

.quote {
  margin-left: 40px;  /* Indents the paragraph from the left */
  margin-right: 40px; /* Indents the paragraph from the right */
  font-style: italic; /* Optional: Italicize the text for a quote */
}

</style>
</head>

<body>
<h1>e-Portfolio for Research Methods and Professional Practice course</h1>
<h2>Chris Butterworth</h2>
<!-- <p><a href="about-me.html">About me</a></p> -->
<p><a href="about-me.html">About me</a></p>
<!-- <p><a href="prep.html">Preparation for Research Methods and Professional Practice module</a></p> -->

<p>GitHub-hosted version: <a href="https://butterworthc.github.io/RMPP/e-Portfolio.html">butterworthc.github.io/RMPP/e-Portfolio.html</a></p>
<p>Online repository, showing commit descriptions: <a href="https://github.com/ButterworthC/RMPP">https://github.com/ButterworthC/RMPP</a></p>


<h2>Unit 1: <!-- Introduction to Research Methods. The Scientific Investigation and -->
Ethics in Computing</h2>
<p><b>Synopsis</b>: This unit introduced the module and went into the types of reasoning, including deductive and inductive, in the context of 
the scientific method. The concept of research ethics was also introduced, along with the following two codes of ethics/conduct:</p>
<p>I found the Association for Computing Machinery's Code of Ethics (<a href="#acm2018">ACM, 2018</a>) and its case studies (<a href="#acmnd">ACM, n.d.</a>), 
and the British Computer Society's Code of Conduct (<a href="#bcs">BCS, 2022</a>),
to be rooted in common sense but, as BCS admits: "It is expected that these rules and professional standards 
will be higher than those established by the general law 
and that they will be enforced through disciplinary action which can result in expulsion from membership."
In other words, these rules are toothless. A statutory framework would have more of a bite and would help close the gap in compliance.</p>
<h3>Reflective Activity 1: Ethics in Computing in the age of Generative AI [943 words]</h3>
<p>The above (<a href="#acm2018">ACM, 2018</a>; <a href="#bcs">BCS, 2022</a>) were just two governance frameworks but a recent paper (<a href="#correa">Corr&ecirc;a et al., 2023</a>) 
examines 200 such frameworks, in the form of a survey of surveys,
aiming "to determine whether a consensus exists regarding the normative discourse presented in ethical guidelines surrounding AI development"
and concluding (like me) that there is a "need for comprehensive and enforceable frameworks to guide ethical AI development and usage."</p>
<p>The authors extracted from the literature a set of 17 principles, which they listed as:</p>
<blockquote class="quote">"accessibility, accountability, auditability, beneficence/non-maleficence, dignity, diversity, freedom/autonomy, human-centeredness, inclusion, intellectual property, justice/equity, open source/fair competition, privacy, reliability, solidarity, sustainability, and transparency/explainability."<br>(<a href="#correa">Corr&ecirc;a et al., 2023</a>)</blockquote>
<p>Although this list of principles was virtually universal, there were differences in emphasis from region to region, according to cultural variations.  In the western world, the reverence for individuality causes the prioritization of principles such as dignity, freedom/autonomy and privacy, whereas in the eastern world, where individuality is more likely to be subsumed by collective interests (<a href="#hofstede">Hofstede, 2011</a>), principles such as accountability, auditability, reliability and solidarity are favoured (<a href="#correa">Corr&ecirc;a et al., 2023</a>).</p>
<p>The analysis was multidimensional, cutting across the above regional cultural variations and existing legislation in different countries, also considering each paper's type (which I think means research vs review), the regulations it advocates, its normativity, and the perceived urgency of the study.  Another dimension was the type of code the different researchers wanted their proposed regulations to form, divided into legislation, voluntary codes, and "recommendation," which I take to be neither of the preceding.  Another was "normative strength," which the authors define as the split between recommendations for guidelines and for legally binding regulations, which confused me because the previous dimension seems to have covered that.  The final dimension was "impact scope," by which the authors meant the timescale over which each paper's AI type will be relevant, divided into "long-termism," "short-termism" and a third category for both.</p>
<p>I found the analysis of all this data in its multiple dimensions to be quite crude, not made more sophisticated by the presentation of the results in Power BI&trade;.
The authors found regional variations in the numbers of papers published and commented on the rapid growth of these in China relative to the United States, 
also observing the dominance of India in the AI field.  
In my opinion it would be enough to have representative papers from each region for comparison of their priorities, without spending too much time comparing their volumes.  
I feel I am justified in this by the authors' contrast between the number of papers from Africa (one!) and the number of 
"African Union member states [which] possess data protection and privacy legislation" (seventeen) (<a href="#kiemde">Kiemde &amp; Kora, 2022</a>).
However, the lack of activity in the United States could be attributed to the prevalence there of a developing country environment 
where regulation is kept to a minimum in order to release entrepreneurial forces (<a href="#schaake">Schaake, 2024</a>).</p>
<p>I was surprised to see that only 25% of the papers were from academic institutions.
The most prolific organisations were governments, private corporations (also a surprise), NGO's and non-profits.
It is good to see that the industry is not afraid to police itself.  The next categories were international organisations, and at 13%, professional associations, 
which makes sense, as there are only one or two relevant ones in each country (<a href="#aaai">AAAI, 2025</a>).</p>
<p>The authors see the average "normative strength" as low:</p>
<blockquote class="quote">This lack of convergence to a more "government-based" form of regulation reflects in the normative strength of these documents, where the vast majority (98%) only serve as "soft laws," i.e., guidelines that do not entail any form of a legal obligation&hellip;<br>(<a href="#correa">Corr&ecirc;a et al., 2023</a>)</blockquote>
<p>I did not see much value in the impact scope, or timescale analysis.  The fact that academic institutions look further ahead than companies seems unsurprising and natural to me.</p>
<p>After going through these dimensions, the authors note that only about half the papers reviewed actually declared their objectives, and that "most of the documents only prescribe normative claims without the means to achieve them" (<a href="#correa">Corr&ecirc;a et al., 2023</a>).  I think I might have excluded many of the papers that failed to make strong cases for their codes.  With only 200 papers this review was never going to be exhaustive anyway.</p>
<p>In the final remarks of <a href="#correa">Corr&ecirc;a et al. (2023)</a>, there seems to be a lack of firm conclusions as to how to harmonise AI codes of ethics worldwide, although their identification of 17 principles would make a good starting point for further analysis.  If I were conducting this, I would grade each paper according to each of those principles and then develop a logical ontology called "AI Ethics" or something similar, which could be used to develop a "common ground" set of principles, and identify areas in which haggling could take place between organisations seeking to produce a unified code of ethics or even supranational legislation.</p>
<p>Unlike the above paper, the British Computer Society's explanation of ethics in AI (<a href="#deckard">Deckard, 2023</a>) is not a review paper and does not appear 
in a peer-reviewed journal but is a page on the BCS website explaining AI ethics to those considering getting into the field.
It does emphasise that AI is an evolving field and that the ethical framework surrounding it must evolve too.
The paper encourages those in the field of AI to get involved in the development of an ethical framework.
I do not see how anyone could object to its recommendations to understand ethics, catch up with the technology and stay abreast of it, communicate, collaborate, 
and participate in the AI ethics debate.  Perhaps the first paper and those it spawns should be a central part of this debate.</p>

<h2>Unit 2: Research Questions, the Literature Review and the Research Proposal</h2>
<p><b>Synopsis</b>: Unit 2 introduces a research question as a specific, logically arguable, and non-trivial query that drives a research project. 
It helps researchers keep focused, so their investigation stays relevant and keeps a coherent structure. 
A good research question defines the scope of inquiry, the data to be collected and how it will be analysed. 
Research evolves, so questions are continually refined based on findings. 
Mind maps can aid this process by visualizing relations between topics. 
Developing a good research question involves reviewing the literature, focusing on a topic, and assessing feasibility. 
A critical literature review is essential to identify gaps in existing studies and to provide references to cite, ensuring academic integrity. 
A good research question is the foundation of a methodical and useful research project.
</p>
<h3>Research Proposal Outline</h3>
**********
<pre>
You should also take some time to consider your research proposal which could be based around the area you have chosen to investigate in your literature review 
or the topic of your capstone project (MSc students).
</pre>
don't forget to replace the above with the answer<br>
**********

<h2>Unit 3: Methodology and Research Methods</h2>
<p><b>Synopsis</b>: Unit 3 established that choosing a research methodology requires an understanding of the underlying assumptions. 
<a href="#saunders">Saunders et al. (2023)</a> highlight ontological, epistemological, and axiological assumptions that drive research design, by planning how to answer research questions. 
Research design can be exploratory (open-ended) or conclusive (focused), including descriptive research, which aims to analyse specific elements. 
Research methods include qualitative (exploring experiences), quantitative (analysing numerical data), and mixed methods. 
Data collection involves primary (direct sources) and secondary (existing literature) research. 
Techniques include surveys, interviews, case studies, and observations. 
Pre- and post-testing help assess changes over time. 
Selecting the right method ensures accurate data collection and interpretation. 
Statistical analysis applies to numerical data, while qualitative insights require careful interpretation. 
Combining methods, like interviews guiding surveys, improves research quality.

</p>
<h3>Research Proposal Review</h3>
**********
<pre>
Considering your thoughts on your chosen area of interest for your project:

    Which of the methods described in this week's reading would you think would suit your purpose?
    Which data collection methods would you consider using?
    Which required skills will you need to have or develop for the chosen project?

Note that you may find that you could be using a mixture of both the research methods and the data collection methods. 
These considerations will be included in your presentation of the Project Proposal in unit 10.
</pre>
don't forget to replace the above with the answers!<br>
**********

<h3>Peer Review Activity</h3>
<p>
I selected two papers on image classification:

<table>
<tr><td></td><th>Image Classification with<br>Classic &amp; Deep Learning Techniques</th><th>A Survey on Semi- Self- and Unsupervised<br>Learning for Image Classification</th></tr>
<tr><th style="text-align: left;">Source</th><td><a href="#lorente">Lorente et al. (2021)</a></td><td><a href="#schmarje">Schmarje et al. (2021)</a></td></tr>
<tr><th style="text-align: left;">Type</th><td>Experimental study</td><td>Survey</td></tr>
<tr><th style="text-align: left;">Purpose</th><td>To compare various kinds of image classifier</td><td>To "compare 34 methods in detail based on their performance"</td></tr>
<tr><th style="text-align: left;">Problem</th><td>Determining the most effective method under different circumstances</td><td>Scarcity of labeled data in training high-performing classifiers</td></tr>
<tr><th style="text-align: left;">Objective</th><td>To assess the performance of these techniques "in terms of accuracy and loss"</td><td>To identify trends, categorize existing approaches, and highlight future research directions</td></tr>
<tr><th style="text-align: left;">Contribution</th><td>Offering insights for researchers and practitioners in choosing suitable classifiers</td><td>Making it easier for new researchers to understand the field's progress and open challenges</td></tr>
<tr><th style="text-align: left;">Appropriateness<br>of research methodology</th><td>It directly tests different classification techniques on benchmark datasets, enabling objective comparisons</td><td>A survey-based approach is appropriate since the goal is to provide a broad synthesis rather than conduct original experiments</td></tr>
<tr><th style="text-align: left;">Appropriateness<br>of data collection<br>and analysis</th><td>Uses widely accepted datasets and performance metrics</td><td>Based on reviewing past studies rather than conducting new experiments</td></tr>
<tr><th style="text-align: left;">Support for claims and conclusions</th><td>Includes "accuracy and loss" comparisons to justify its claims but significance testing could strengthen its conclusions</td><td>Relies on external studies to support its claims</td></tr>
<tr><th style="text-align: left;">Enhancements</th><td>I would test on more datasets to confirm accuracy, and change some parameters to ensure the model is optimised</td><td>Perhaps include a side-by-side comparison of methodologies, and talk more about potential biases</td></tr>

</table>

</p>



<h2>Unit 4: Case Studies, Focus Groups and Observations</h2>
<p><b>Synopsis</b>: Unit 4 introduced some data collection methods. 
Case studies involve detailed research on individuals or groups, generating hypotheses and deeper investigation of the question, but they are unsuitable for establishing causality due to researcher bias and atypical respondents, limiting generalizability. 
Focus groups, another qualitative method, gather insights from small groups of participants with similar backgrounds. 
They can answer "why," "what," and "how" questions but need careful selection of participants. 
Quantitative observation involves measuring, as accurately and precisely as possible, numerical physical values through experiments, processing the results by statistical analysis. 
Qualitative observation (as opposed to experimentation) monitors characteristics remotely, ensuring activity occurs in a natural environment. 
In descriptive research, researchers may observe or participate, and can therefore influence data collection approaches and the data collected.</p>
<h3>Unit 4 Seminar: Case Study on Privacy</h3>
Beth asks Ricardo to retrieve names and addresses, so she can contact people for information and permission to use it.<br>
<ul>
<li>As Ricardo is not responsible for determining allowable access, he should not release it to Beth, as this would be a violation of GDPR's
lawfulness, fairness, and transparency principles (<a href="#eu2016">European Union, 2016</a>).</li>
<li>If he did have authority, he should still respect people's privacy rights (under GDPR again) to maintain public trust.</li>
<li>Beth should not contact people directly to let them opt in but go through her department.</li>
<li>For Beth to proceed she should perhaps adjust the boundary under study until she reaches 50% coverage, but this could skew the data.</li>
</ul>

 
<h2>Unit 5: Interviews, Survey Methods, and Questionnaire Design</h2>
<p><b>Synopsis</b>: Unit 5 introduced interviews, surveys, and questionnaires as essential research tools. 
Detailed interviews, common in qualitative studies, let detailed insights be obtained from individuals. 
Surveys, which are more quantitative in nature, aggregate opinions and trends in various formats, including online polls. 
A survey is broader than a questionnaire, as it enables data to be analysed, whereas a questionnaire is just a set of questions used in surveys. 
Effective questionnaire design follows several key steps, such as defining respondents, question selection, and pre-testing. 
Closed questions offer structured, easily analysed data, whereas open questions provide insights but are harder to interpret in bulk. 
Ethical considerations like confidentiality are crucial. 
Properly designed questionnaires avoid leading, assumptive, or ambiguous questions, ensuring meaningful, reliable responses for research success.

</p>
<h3>Reflective Activity 2: Inappropriate Use of Surveys</h3>
<p>The Cambridge Analytica scandal, where innocent-looking Facebook surveys were combined to build up psychological and political profiles of 
unsuspecting users (<a href="#confessore">Confessore, 2018</a>), was made possible by the lack of safeguards against such profiling activities at Facebook and by the 
unethical culture of what seems to have been almost a mercenary organisation whose aims were to influence the outcomes of elections (<a href="#kleinman">Kleinman, 2018</a>).</p>
<p>A similar scandal involved the Conservative Party's polling activities during the 2019 election campaign.
They used Facebook to run surveys on the National Health Service, which were then used to profile voters.
At the time a solicitor was quoted as saying: "In my view the Conservative Party's method of obtaining consent is invalid...
this is a clear breach of the Data Protection Act 2018" (<a href="#dodds">Dodds, 2019</a>).</p>
<p>Ethically these activities violated Section 1.6 (Respect Privacy) of the Association for Computing Machinery's Code of Ethics and Professional Conduct
(<a href="#acm2018">ACM, 2018</a>). The social fallout involved the undermining of the democratic process and the loss of individual autonomy.
Legally, the case hurt Facebook as they were fined $5 billion by the FTC (<a href="#ftc">Federal Trade Commission, 2019</a>).
Legislation resulted from the scandal in the form of GDPR, the European Union's General Data Protection Regulation (<a href="#privacy">Privacy International, 2019</a>).
From an I.T. professional standpoint, Cambridge Analytica breached the Association for Computing Machines Code of Ethics and Professional Conduct, 
Sections 1.2 (Avoid Harm), 1.6 (Respect Privacy) and 1.7 (Honour Confidentiality) (<a href="#acm2018">ACM, 2018</a>).</p>

<h2>Unit 6: Quantitative Methods - Descriptive and Inferential Statistics</h2>
<p><b>Synopsis</b>: This unit consisted of a couple of readings from <a href="#berenson">Berenson, L. et al. (2019)</a>, the first being from Chapter 2,
about visualising variables in tables and graphics. The variables and their representations are:
</p>
<table>
<tr><th>Variable Type</th><th>Visualisation</th></tr>
<tr><td>Categorical</td><td>Summary Table<br>Contingency Table</td></tr>
<tr><td>Numerical</td><td>Frequency Distribution<br>Classes &amp; Bins<br>Relative Frequency Distribution<br>Percentage Distribution<br>Cumulative Distribution</td></tr>
<tr><td>Categorical</td><td>Bar Chart<br>Pie &amp; Doughnut Chart<br>Pareto Chart</td></tr>
<tr><td>Numerical - one</td><td>Stem and Leaf Display<br>Histogram<br>Percentage Polygon<br>Ogive</td></tr>
<tr><td>Numerical - two</td><td>Scatter Plot<br>Time Series</td></tr>
</table>
<p>Examples are given in Excel&trade;, JMP&trade; and Minitab&trade; formats.</p>
<p>The second reading is from Chapter 3 of <a href="#berenson">Berenson, L. et al. (2019)</a>, which is about descriptive measures of numerical data,
such as mean, median, mode, geometric mean, range, variance, standard deviation, z-score etc. 
Distributions and skewness are drawn, then quartiles, covariance and correlation.</p>

<h2>Unit 7: Inferential Statistics and Hypothesis Testing</h2>
<p><b>Synopsis</b>: This unit introduced the summary measures that can be derived from datasets, and started by defining four levels of measurement, 
which I noticed spell out the acronym <i>noir</i> when placed in order of ascending informativeness.  
This stands for nominal and ordinal (the two qualitative measures), and interval and ratio, (the two quantitative measures).  
Discrete variables (integers) and continuous variables (real numbers) are discussed.  
Bar charts and histograms are illustrated, with examples of normal and skewed distributions.  
Summary measures such as mean, median, standard deviation, quartile, are defined, and then hypothesis testing is introduced.  
The readings in <a href="#berenson">Berenson et al., 2019</a> go into great detail about hypothesis testing, and this was quite a heavy unit.
</p>

<h3>Hypothesis Testing Worksheets</h3>
<p>
<b>The Related Samples T Test</b><br>
<img src="images/hypothesis_testing_01_related_samples_t_test.jpg" /><br clear="all">
In this test, Con1 has a higher mean than Con2.<br>
<b>Two Tailed Test</b><br>
The two-tailed p-value is 0.0183, much less than the alpha level of 0.05, so there is a statistically significant difference between Con1 and Con2.
The upper critical value for a two-tailed test at Î± = 0.05 is 2.262, and the t-statistic is 2.875, in the rejection zone.
Therefore the null hypothesis, i.e. that there is no mean difference between Con1 and Con2, is rejected.
So there is a difference, and the Pearson correlation of 0.8633 suggests the paired observations are strongly related.<br>
<b>One Tailed Test</b><br>
The null hypothesis is rejected again because the one-tailed p-value is 0.0092, even lower than before, and much less than the alpha level of 0.05, 
and the t-statistic of 2.875 is still in the rejection zone because the critical value for a one-tailed test at Î± = 0.05 is 1.833.
</p>
<p>
<b>The Independent Samples T Test</b><br>
First perform an F test to determin which form of the independent samples t test to use:<br>
<img src="images/hypothesis_testing_02_independent_samples_t_test.jpg" /><br clear="all">
I had to do some detective work to get the right answer to this one because the instructions for LibreOffice contained an incorrect cell reference,
i.e. for I14, the value for "p2", which was given as =I11*2.  I quickly noticed that this was spurious and corrected it to =I12*2.
The result is that F, 0.8385, is between the critical limits of 0.6222 and 1.6073, and that the value of P2, 0.5399, is a lot more than &alpha;, 0.05, 
meaning the null hypothesis is not rejected and that at a 5% significance level, there is no significant difference in the variances.
Therefore the equal variances form of the independent samples t test should be used:<br>
<img src="images/hypothesis_testing_02_independent_samples_t_test2.jpg" /><br clear="all">
This yields a value of 0.002752, which is much smaller than 0.05, so the null hypothesis, that there is no significant difference in the means
of the datasets, is rejected and we conclude that their means are significantly different.
</p>

<h2>Unit 8: Data Analysis and Visualisation</h2>
<p><b>Synopsis</b>: Chapter 1 of <a href="#berenson">Berenson et al., 2019</a> starts by describing the first step in data analysis, defining variables.
They are either numerical, for example discrete numbers of tickets sold, continuous values of people's heights, or categorical, for example nationality.
Ordering of values is defined by a measurement scale, which is called a ratio scale if it includes a zero point, otherwise an interval scale.
Categorical values can be on a nominal scale, i.e. names with no order, or an ordinal scale, where categories are ranked.
The collection of data is discussed, including the difference between populations (summarised by parameters) and samples (summarized by statistics),
followed by data cleaning, formatting, survey errors, and random sampling, with and without replacement.
Many of these ideas are presented more succinctly in the O'Reilly book on Practical Statistics we used in the Data Analysis module (<a href="#bruce">Bruce et al., 2020</a>: 47-57).
Later chapters of <a href="#berenson">Berenson et al., 2019</a> discuss business analytics and the future of data analysis.
</p>

<h2>Unit 9: Validity and Generalisability in Research</h2>
<p><b>Synopsis</b>: 

</p>

<h2>Unit 10: Research Writing</h2>
<p><b>Synopsis</b>: 

</p>

<h2>Unit 11: Professional Development</h2>
<p><b>Synopsis</b>: 

</p>

<h2>Unit 12: Project Management and Managing Risk</h2>
<p><b>Synopsis</b>: 

</p>

<p></p>



<p>&nbsp;</p>
<p>&nbsp;</p>

<h2>References</h2>

<p id="aaai">AAAI. (2025) Association for the Advancement of Artificial Intelligence List of Societies. Available from: <a href="https://aaai.org/about-aaai/aaai-resources/ai-international/societies/">aaai.org/about-aaai/aaai-resources/ai-international/societies/</a> [Accessed 4 March 2025].</p>
<p id="acm2018">ACM. (2018) ACM Code of Ethics and Professional Conduct. Available from: <a href="https://www.acm.org/code-of-ethics">https://www.acm.org/code-of-ethics</a> [Accessed 31 January 2025].</p>
<p id="acmnd">ACM. (n.d.) Code of Ethics: Case studies. Available from: <a href="https://www.acm.org/code-of-ethics/case-studies">https://www.acm.org/code-of-ethics/case-studies</a> [Accessed 31 January 2025].</p>
<p id="bcs">BCS. (2022) BCS, The Chartered Institute for IT. The Code of Conduct. Available from: <a href="https://www.bcs.org/media/2211/bcs-code-of-conduct.pdf">https://www.bcs.org/media/2211/bcs-code-of-conduct.pdf</a> [Accessed 1 February 2025]</p>
<p id="berenson">Berenson, L. et al. (2019) <i>Basic Business Statistics: Concepts and Applications</i>. 14th ed. Harlow: Pearson.</p>
<p id="bruce">Bruce P, Bruce, A. &amp; Gedeck, P. (2019) <i>Practical Statistics for Data Scientists</i>. 2nd ed. Sebastopol, CA: O'Reilly Media Inc.</p>
<p id="confessore">Confessore, N. (2018) Cambridge Analytica and Facebook: The Scandal and the Fallout So Far. <i>The New York Times</i>. Available from: <a href="https://www.nytimes.com/2018/04/04/us/politics/cambridge-analytica-scandal-fallout.html">www.nytimes.com/2018/04/04/us/politics/cambridge-analytica-scandal-fallout.html</a> [Accessed 6 March 2025].</p>
<p id="correa">Corr&ecirc;a, N.K. et al. (2023) Worldwide AI ethics: A review of 200 guidelines and recommendations for AI governance. <i>Patterns</i> 4(10). DOI: <a href="https://doi.org/10.1016/j.patter.2023.100857">https://doi.org/10.1016/j.patter.2023.100857</a></p>
<p id="deckard">Deckard, R. (2023) <i>What are Ethics in AI</i>. BCS. Available from <a href="https://www.bcs.org/articles-opinion-and-research/what-are-ethics-in-ai/">www.bcs.org/articles-opinion-and-research/what-are-ethics-in-ai/</a> [Accessed 2 February 2025].</p>
<p id="dodds">Dodds, I. (2019) Tories may have broken law in compiling voter data via polls spread on Facebook. The Telegraph. Available from: <a href="https://www.telegraph.co.uk/technology/2019/12/03/conservatives-used-facebook-surveys-games-hoover-voter-data/">www.telegraph.co.uk/technology/2019/12/03/conservatives-used-facebook-surveys-games-hoover-voter-data/</a> [Accessed 10 March 2025].</p>
<p id="eu2016">European Union (2016) Regulation (EU) 2016/679 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regard to the processing of personal data and on the free movement of such data, and repealing Directive 95/46/EC (General Data Protection Regulation). Official Journal of the European Union L 119, 4 May, pp. 1-88. Available from: <a href="https://eur-lex.europa.eu/eli/reg/2016/679/oj">https://eur-lex.europa.eu/eli/reg/2016/679/oj</a> [Accessed: 19 February 2025].</p>
<p id="ftc">Federal Trade Commission (2019) FTC Imposes $5 Billion Penalty and Sweeping New Privacy Restrictions on Facebook. Available from: <a href="https://www.ftc.gov/news-events/news/press-releases/2019/07/ftc-imposes-5-billion-penalty-sweeping-new-privacy-restrictions-facebook">www.ftc.gov/news-events/news/press-releases/2019/07/ftc-imposes-5-billion-penalty-sweeping-new-privacy-restrictions-facebook</a> [Accessed 10 March 2025].</p>
<p id="hofstede">Hofstede, G. (2011) Dimensionalizing Cultures: The Hofstede Model in Context. <i>Online Readings in Psychology and Culture</i> 2(1). DOI: <a href="https://doi.org/10.9707/2307-0919.1014">doi.org/10.9707/2307-0919.1014</a></p>
<p id="kiemde">Kiemde, S.M.A. &amp; Kora, A.D. (2022) Towards an ethics of AI in Africa: rule of education. <i>AI and Ethics</i> 2: 35-40. DOI: <a href="https://doi.org/10.1007/s43681-021-00106-8">doi.org/10.1007/s43681-021-00106-8</a></p>
<p id="kleinman">Kleinman, Z. (2018) Cambridge Analytica: The story so far. BBC. Available from: <a href="https://www.bbc.co.uk/news/technology-43465968">www.bbc.co.uk/news/technology-43465968</a> [Accessed 10 March 2025].</p>
<p id="lorente">Lorente, O., Riera, I. &amp; Rana, A. (2021) Image Classification with Classic and Deep Learning Techniques. <i>arXiv</i>. DOI: <a href="https://doi.org/10.48550/arXiv.2105.04895">doi.org/10.48550/arXiv.2105.04895</a></p>
<p id="privacy">Privacy International. (2019) Cambridge Analytica, GDPR - 1 year on - a lot of words and some action. Available from: <a href="https://www.privacyinternational.org/news-analysis/2857/cambridge-analytica-gdpr-1-year-lot-words-and-some-action">www.privacyinternational.org/news-analysis/2857/cambridge-analytica-gdpr-1-year-lot-words-and-some-action</a> [Accessed 10 March 2025].</p>
<!-- <p id="priya">Priya, A. (2021) Case Study Methodology of Qualitative Research: Key Attributes and Navigating the Conundrums in its Application. <i>Sociological bulletin</i>. 70(1): 94–110. DOI: <a href="https://doi.org/10.1177/0038022920970318">doi.org/10.1177/0038022920970318</a></p> -->
<p id="schaake">Schaake, M. (2024) Lobbying for unfettered innovation is bad for democracy. <i>Financial Times</i>. Available from: <a href="https://www.ft.com/content/ab2761bd-ace7-428b-aa3e-b7412ef69b48">www.ft.com/content/ab2761bd-ace7-428b-aa3e-b7412ef69b48</a> [Accessed 4 February 2025].</p>
<p id="schmarje">Schmarje, L. et al. (2021) A Survey on Semi- Self- and Unsupervised Learning for Image Classification. <i>IEEE Access</i>. DOI: <a href="http://dx.doi.org/10.1109/ACCESS.2021.3084358">dx.doi.org/10.1109/ACCESS.2021.3084358</a></p>
<p id="saunders">Saunders, M., Lewis, P. &amp; Thornhill, A. (2012) <i>Research Methods for Business Students</i>. 6th ed. Pearson Education Limited.</p>

<p>Power BI&trade; is a trademark of Microsoft Corporation</p>

<p>&nbsp;</p>
<p>&nbsp;</p>

</body>
</html>